{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PointNet++ для семантической сегментации облака точек\n",
        "\n",
        "Этот ноутбук настраивает окружение и запускает обучение модели PointNet++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Установка зависимостей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка всех необходимых библиотек\n",
        "%pip install torch torchvision numpy scikit-learn tqdm matplotlib tensorboard -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Клонирование репозитория или загрузка файлов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Клонировать репозиторий (данные уже включены!)\n",
        "!git clone https://github.com/JohnSili/pointnet2-segmentation.git\n",
        "%cd pointnet2-segmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Распаковка данных\n",
        "\n",
        "**Данные уже включены в репозиторий!** Архив `data_for_colab.zip` содержит 500 PLY файлов.\n",
        "\n",
        "Если нужно загрузить свои данные, используйте вариант B ниже.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Распаковать данные из репозитория\n",
        "if os.path.exists('data_for_colab.zip'):\n",
        "    print(\"Распаковка данных...\")\n",
        "    with zipfile.ZipFile('data_for_colab.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    print(\"✓ Данные распакованы!\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Архив данных не найден! Убедитесь, что репозиторий клонирован полностью.\")\n",
        "\n",
        "# Проверка наличия данных\n",
        "data_dir = '3011-20251217T195928Z-1-001'\n",
        "area = '3011'\n",
        "if not os.path.exists(os.path.join(data_dir, area)):\n",
        "    raise FileNotFoundError(f\"Данные не найдены в {data_dir}/{area}\")\n",
        "\n",
        "ply_files = [f for f in os.listdir(os.path.join(data_dir, area)) if f.endswith('.ply')]\n",
        "print(f\"✓ Найдено {len(ply_files)} PLY файлов\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Проверка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataset import S3DISDataset\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Используем реальные данные\n",
        "data_dir = '3011-20251217T195928Z-1-001'\n",
        "area = '3011'\n",
        "\n",
        "# Проверка данных\n",
        "print(\"Проверка данных...\")\n",
        "dataset = S3DISDataset(data_dir, area=area, split='train', num_points=2048)\n",
        "points, labels = dataset[0]\n",
        "unique_classes = sorted(torch.unique(labels).tolist())\n",
        "\n",
        "print(f\"✓ Датасет: {len(dataset)} файлов\")\n",
        "print(f\"✓ Форма: {points.shape[0]} точек, {points.shape[1]} признаков\")\n",
        "print(f\"✓ Классы: {unique_classes} ({len(unique_classes)} классов)\")\n",
        "\n",
        "# Сохраняем для использования в обучении\n",
        "DATA_DIR = data_dir\n",
        "AREA = area\n",
        "NUM_CLASSES = len(unique_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Обучение модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Запуск обучения\n",
        "!python train.py \\\n",
        "    --data_dir {DATA_DIR} \\\n",
        "    --area {AREA} \\\n",
        "    --num_points 2048 \\\n",
        "    --batch_size 8 \\\n",
        "    --epochs 50 \\\n",
        "    --lr 0.001 \\\n",
        "    --num_classes {NUM_CLASSES} \\\n",
        "    --device cuda \\\n",
        "    --save_dir ./checkpoints \\\n",
        "    --log_dir ./logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Мониторинг обучения (TensorBoard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Запуск TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Тестирование модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python test.py \\\n",
        "    --data_dir {DATA_DIR} \\\n",
        "    --area {AREA} \\\n",
        "    --checkpoint ./checkpoints/best_model.pth \\\n",
        "    --num_classes {NUM_CLASSES}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Визуализация результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python visualize.py \\\n",
        "    --data_dir {DATA_DIR} \\\n",
        "    --area {AREA} \\\n",
        "    --checkpoint ./checkpoints/best_model.pth \\\n",
        "    --num_samples 5 \\\n",
        "    --output_dir ./visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Скачивание результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Создаем архив с результатами\n",
        "with zipfile.ZipFile('results.zip', 'w') as zipf:\n",
        "    if os.path.exists('checkpoints'):\n",
        "        for root, dirs, files_list in os.walk('checkpoints'):\n",
        "            for file in files_list:\n",
        "                zipf.write(os.path.join(root, file))\n",
        "    if os.path.exists('visualizations'):\n",
        "        for root, dirs, files_list in os.walk('visualizations'):\n",
        "            for file in files_list:\n",
        "                zipf.write(os.path.join(root, file))\n",
        "\n",
        "# Скачиваем архив\n",
        "files.download('results.zip')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
